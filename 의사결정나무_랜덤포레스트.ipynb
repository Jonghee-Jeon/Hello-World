{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 의사결정나무 (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " * 결정트리는 매우 간단하지만 강력한 지도 학습기법이다. 이 모델의 중요한 장점은 사람이 쉽게 이해 할 수 있고, 새로운 인스턴스의 목적 범주를 예측하기 위해 결정 트리를 따라 결정한다는 것이다. 의사결정나무의 예측력은 다른 지도 학습 기법들에 비해 대체로 떨어지나 해석력이 좋으며 생성된 규칙은 if-then 형식으로 표현되어 이해가 쉽고 SQL과 같은 데이터베이스 언어로 쉽게 구현되는 장점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 의사결정나무의 구성요소\n",
    " - 뿌리마디(root node): 시작되는 마디로 전체 자료를 포함\n",
    " - 자식마디(child node): 하나의 마디로부터 분리되어 나간 2개 이상의 마디들\n",
    " - 부모마디(parent node): 주어진 마디의 상위마디\n",
    " - 끝마디(terminal node): 자식마디가 없는 마디\n",
    " - 중간마디(internal node): 부모마디와 자식마디가 모두 있는 마디\n",
    " - 가지(branch): 뿌리마디로부터 끝마디까지 연결된 마디들\n",
    " - 깊이(depth): 뿌리마디부터 끝마디까지의 중간마디들의 수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 출력변수가 연속형인 회귀나무\n",
    " - 범주형인 분류나무"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 성장, 가지치기, 타당성 평가, 해석 및 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - 성장 : 각 마디에서 적절한 최적의 분리규칙을 찾아서 나무를 나무를 성장시키는 과정으로서 적절한 정지규칙을 만족하면 중단\n",
    "  - 가지치기 : 오차를 크게 할 위험이 높거나 부적절한 추론규칙을 가리고 있는 가지 또는 불필요한 가지를 제거\n",
    "  - 타당성 평가 : 이익도표 혹은 시험자료를 이용하여 의사결정나무를 평가\n",
    "  - 해석 및 예측 : 구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 여러 가지 의사결정나무 알고리즘\n",
    "  - CART(classification and regression trees)\n",
    "   : 가장 널리 사용되는 의사결정나무 알고리즘, 불순도의 측도로서 출력변수가 범주형인 경우 지니지수를 이용하고 출력변수가 연속형인 경우에는 분산을 이용하여 이진분리(binary split)를 한다. 개별 입력변수뿐만 아니라 입력변수들의 선형결합들중에서 최적의 분리를 찾을 수도 있다.\n",
    "  - C4.5와 C5.0\n",
    "   : CART와는 다르게 각 마디에서 다지분리(multiple split)가 가능하며 범주형 입력변수에 대해서는 범주의 수만큼 분리가 일어난다. 불순도의 측도로는 엔트로피지수를 사용한다\n",
    "  - CHAID(chi-squared automatic interaction detection)\n",
    "   : 가지치기를 하지 않고 적당한 크기에서 나무모형의 성장을 중지하며 입력변수가 반드시 범주형 변수이어야 한다. 불순도의 측도로는 카이제곱 통계량을 사용한다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 의사결정트리의 장점\n",
    "   - 결정트리를 통한 데이터 분석의 결과는 나무(Tree) 구조로 표현되기 때문에 분석가가 결과를 쉽게 이해하고 설명할 수 있는 장점이 있다. 분류율에 대한 정확도만 따지자면 신경망(Neural Network) 또는 로지스틱 회귀분석 등의 분류 방법들 보다 낮게 평가되기도 하지만 결과를 쉽게 이해하고 설명할 수 있으며 의사결정을 하는데 직접적으로 사용할 수 있는 장점이 있기 때문에 데이터마이닝 적용시 매우 많이 사용되고 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 의결정트리의 단점\n",
    "  - 출력변수가 연속현인 회귀모형에서는 그 예측력이 떨어지며, 일반적으로 복잡한 나무모형은 예측력이 저하되고 해석 또한 어려우며, 상황에 따라 계산량이 많을 수도 있으며, 베이즈 분류경계가 사각형이 아닌 경우네느 좋지 않은 결과를 줄 수 있다는 것이다. 특히, 자료에 약간의 변화가 있는 경우에 전혀 다른 결과를 줄 수 있는(즉, 분산이 매우큰) 불안정한 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 학습법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 앙상블이란 주어진 자료로부터 여러개의 예측모형들을 만든 후 여러한 예측모형들을 결합하여 하나의 최종 예측모형을 만드는 방법\n",
    " - 학습 알고리즘(learning algorithm)들을 따로 쓰는 경우에 비해 더 좋은 예측 성능을 얻기위해 다수의 학습 알고리즘을 사용하는 방법\n",
    " - 예시) 배깅, 부스팅, 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 배깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " - bootstrap aggregating의 줄임말로 통계적 분류와 회귀 분석에서 사용되는 기계 학습 알고리즘의 안정성과 정확도를 향상시키기 위해 고안된 일종의 앙상블 학습법의 메타 알고리즘\n",
    " - 주어진 데이터에 대해서 여러 개의 붓스트랩(bootstrap) 자료를 생성하고 각 붓스트랩 자료를 모델링한 후 결합하여 최종의 예측 모형을 산출하는 방법.\n",
    " - 붓스트랩 자료란 단순 복원임의추출법을 통해 원자료로부터 크기가 동일한 여러 개의 표본 자료를 말함\n",
    " - 원자료로부터 여러 번의 복원 샘플링을 통해 예측 모형의 분산을 줄여 줌으로써 예측력을 향상 시키는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " - 의사결정나무(desicion tree)의 확장개념\n",
    " - 의사결정나무는 동일한 하나의 데이터 집합(Data set)에서 한 번의 훈련용 데이터(training)를 생성하고 하나의 트리(tree)를 생성하고 목표변수를 예측하지만 랜덤 포레스트는 동일한 하나의 데이터 집합에서 임의의 복원 샘플링을 통해 여러 개의 훈련용 데이터를 만들어 여러번의 학습을 통해 여러 개의 트리 생성하고 이들을 결합해 최정적으로 목표변수를 예측함\n",
    " - 랜덤 포레스트 모형은 앙상블 기법인 배깅방법과 임의 노드 최적화라고 할 수 있으며, 임의 노드 최적화는 랜덤하게 분석에 사용되는 변수를 추출해 낸다고 볼 수 있다.\n",
    " - 즉, 배깅과 임의 노드 최적화를 이용한 랜덤 포레스트 모형은 분석을 위해 준비된 데이터로 부터 임의복원추출을 통해 n개의 학습용 데이터를 추출하고 각각 개별적으로 학습을 시켜 트리를 생성하여 마지막 예측 결과를 투표 혹은 확률 등을 이용하여 최종 목표변수를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 의사결정나무 대신 랜덤포레스트 모형을 사용하는 이유?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ☆ 의사결정나무는 이상치 또한 하나의 노드로 구성할 수 있기 대무넹 편향에된 분포에 민감하지 않으나, 큰 분포를 가지고 있기 때문에 노드를 결정 짓게 되는 매개변수의 영향이 아주 크기 때문에, 깊이가 깊은 단일 의사결정나무는 과대적합의 위험이 크다. 하지만 배깅을 이용해 각 트리의 평균, 확률 혹은 투표를 통해 목표변수를 예측한ㄴ 랜덤 포레스트의 경우, 트리들의 편향은 그대로 유지가 되면서, 분산은 감소하기 때문에 보다 안정적(일반화)이며 정확도 성능이 높아지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
